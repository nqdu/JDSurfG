\documentclass[UTF8]{article}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage{caption}
\usepackage{graphicx, subfig}
%\usepackage{noindent}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{enumitem}
\usepackage[colorlinks,linkcolor=blue,citecolor=blue]{hyperref}
\usepackage{bm}
% biblio
\usepackage[authoryear]{natbib}

\lstset{
    basicstyle   =   \sffamily,          % code style
    keywordstyle =   \bfseries,          % keyword 
    commentstyle =   \rmfamily\itshape,  % style of comments
    stringstyle  =   \ttfamily,  % style of strings
    flexiblecolumns,                % 
    numbers      =   left,   % location of line number
    showspaces   =   false,  % 
    numberstyle  =   \tiny \ttfamily,    
    showstringspaces  =   false,
    captionpos          =   t,     
    frame               =   lrtb,   % frame
}

\title{\textbf{Manual of JDSurfG}}
\author{Nanqiao Du and Tingwei Yang \\ Version 4.0}
\date{\today}

\setlength{\listparindent}{0pt}
\begin{document}
\maketitle
\tableofcontents
\newpage


\section{Introduction}
This document describes how to use \texttt{JDSurfG} package 
to perform 3-D joint inversion of shear wave velocity
in crust and upper mantle by surface wave dispersion and
gravity anomaly data. This package is consisted of three
independent modules: generating gravity matrix in spherical
coordinates, conducting direct surface wave tomographic 
inversion, and performing tomographic joint inversion of 
dispersion and gravity anomaly data. In joint inversion, we
utilize direct surface wave tomography method \citep{Fang2015}
to compute 3-D (pseudo) sensitivity kernel of surface waves
traveltime, and the adaptive Gauss-Legendre integration 
method \citep{RN35} is adopted to calculate the gravity 
forward matrix. Based on empirical relations between seismic
velocity and density of rocks \citep{Brocher05}, this 
package would be a useful tool to investigate 3-D shear 
wave structure in the crust and upper mantle. For more details, 
please refer to the paper \citep{Du2021} \\

This package is written by \texttt{C++} and \texttt{Fortran}.
\texttt{C++} is responsible for the main logic such as 
handling I/O, providing useful data structures and 
interfaces. And the \texttt{Fortran} part, derived from 
package \href{https://github.com/HongjianFang/DSurfTomo/tree/stable/src}{DSurfTomo}
with several important modifications (parallel mode, group velocity ray-tracing and analytical derivatives), is used to 
compute surface wave traveltimes and corresponding 1D/3D 
sensitivity kernels.\\

I should note that this package was only tested by 
several people on similar computational conditions, 
so it might contain some bugs in it. I'd appreciate 
to receive bug reporting and modify some part of 
it when obtaining good suggestions. In the long term, 
I would add some new functions to this package, 

\section{Preliminaries}
This package utilizes \texttt{C++} library \href{http://eigen.tuxfamily.org/index.php?title=Main_Page}{Eigen}
to handle multi-dimensional arrays, So you need 
to install it in your own computer before
compiling this package. Also, you should make sure
that your \texttt{C++} compiler support \texttt{C++11}
standards (\texttt{GCC} $\geq$ 4.8).

The package can be installed by using the \href{https://cmake.org/}{CMake} building system. You should make sure your \texttt{cmake} $\geq$ 3.1.0.

\section{Installation}
After you have downloaded the code from Github,
you can compile it by using
\begin{lstlisting}[language=bash]
    cd JDSurfG
    mkdir build; cd build;
    cmake .. -DCXX=g++ -DFC=gfortran -DEIGEN_INC=/path/to/eigen
    make -j4
\end{lstlisting}
Then you will find four executable files in the 
directory \texttt{bin/}:
\begin{lstlisting}[language=bash]
    mkmat DSurfTomo JointSG syngrav  
\end{lstlisting}
That means you have finished installation. \\

If you want to check some functionalities in the package, you can use the command:
\begin{lstlisting}[language=bash]
cmake .. -DCXX=g++ -DFC=gfortran -DEIGEN_INC=/path/to/eigen \
        -DBUILD_TEST=TRUE;
make -j4
\end{lstlisting}

\section{Direct Surface Wave Tomography Module} 
This module need 3 (4 if checkerboard or other test 
is required) input files:
\begin{itemize}
\item \verb!DSurfTomo.in!: contains information of 
        input model, dispersion data and inversion 
        parameters.
\item \verb!surfdataSC.dat!: dispersion data for 
            each station pair
\item \verb!MOD!: Initial model
\item \verb!MOD.true!: True model (if 
                        additional tests are required )
\end{itemize}
There are some points to note before we precede to the 
format of each file:
\begin{enumerate}[(1)]
    \item Input model is homogeneous in latitudinal and 
            longitudinal direction, but the grid size 
            could vary in depth direction.
    \item The input model should be slightly larger than
          the target one in order to perform \texttt{B-Spline}
          smoothing for forward computation. To be specific,
         if our target model is in region 
         $(lat_0 \sim lat_1,lon_0\sim lon_1,0\sim dep_1)$, 
        you should edit your input model at least in 
        region $(lat_0-dlat \sim lat_1+dlat, lon_0-dlon \sim lon_1+dlon,0 \sim dep_1+dz)$.
    \item Stations should be far away enough from target model 
            boundaries, or some warnings will be given 
            when you running this package. This is to 
            avoid that surface wave train travels along
            the models' boundaries.
\end{enumerate}
Now there are the formats of every file below:
\subsection{Parameter File} \label{DSurfTomo}
The parameter file is called \texttt{DSurfTomo.in}
in this instruction. It is a self-explanatory file.
Here is a template of this file below:
\\
\begin{lstlisting}
# DSurfTomo inversion Parameters

# # of iterations
NITERS =  16
ITER_CURRENT = 0 # current iteration


#  minimum velocity, maximum velocity in km/s
MIN_VELOC =  2.0
MAX_VELOC = 5.0 

# synthetic test
SYN_TEST = 1                # synthetic flag(0:real data,1:synthetic)
NOISE_LEVEL = 1.5          #  noise level, std value of gaussian noise

# inverse method: LSMR = 0 CG = 1 LBFGS = 2
INV_METHOD = 2

# for LSMR-based inversion 
SMOOTH = 15.0  # 2-nd Tikhonov regularization parameter
DAMP = 0.01    # damping parameter for LSMR
NTHREADS =  2  # # of threads used in LSMR solver 

# for CG/LBFGS parameters 
SMOOTH_IN_KM = 0 # smooth parameters are in km/rescale, 
SIGMA_H = 0.25    # smoothing parameters in horizonal, KM or [0-1]  
SIGMA_V = 0.25   # smoothing parameters in vertical
ITER_START = 0   # use information after this flag

# line search 
MAX_REL_STEP = 0.04  # max relative variation for next model

\end{lstlisting}
When you run this program, it will automatically skip
all the empty lines and comments (denoted by '\#'). So you 
could modify this file (by adding your own comments) Now let's
see the meaning of each parameter in the template file.

\begin{description}
\item \texttt{NITERS} Number of iterations it need to run.
\item \texttt{ITER\_CURRENT} Current iteration of the initial model. If set to 10, the initial model will be indexed as \texttt{mod\_iter10} in the result directory. This option can be useful if you want more iterations.
\item \texttt{MIN/MAX\_VELOC} Minimum and maximum velocity permitted. This option provide the prior constraints on the result shear wave velocity model.
\item \texttt{SYN\_TEST} Do synthetic test. The \texttt{MOD.true} file should be provided in this case.
\item \texttt{NOISE\_LEVEL} The Gaussian noise level added to synthetic data as observations. It is defined as:
\[   
    d_{obs}^i = d_{syn}^i +  noiselevel * N(0,1)
\]
\item \texttt{INV\_METHOD} Choose the inversion method you want. I strongly recommend LSMR (for small scale problems) and L-BFGS (large scale).
\item \texttt{SMOOTH} and \texttt{Damp} The second and first Tikhonov regularization coefficients used in inversion. The two parameters only work when \texttt{INV\_METHOD} = 0 (LSMR mode).
\item \texttt{NTRHEADS} Number of threads used in LSMR solver. Usually 2-4 is enough.
\item \texttt{SMOOTH\_IN\_KM} Choose the smoothing operation in NLCG/L-BFGS inversion. Note that in NLCG/L-BFGS iterations, we don't apply Tikhonov regularization. Instead, we just convolve the search direction with a Gaussian smoothing function.
\item \texttt{SIGMA\_H,SIGMA\_V} Gaussian smoothing parameters in horizontal and vertical direction.  The search direction wiil be smoothed as:
\[
\bar{g}(\bm{x}) = \frac{1}{W(\bm{x})} \int_V g(\bm{x}) e^{- \frac{1}{2} x^T \Sigma^{-1} x} \rm{d}V
\]
where $W(\bm{x})$ is the normalization factor: 
\[
W(\bm{x}) = \int_V e^{-\frac{1}{2} x^T \Sigma^{-1} x} \rm{d}V
\]
and $\Sigma = Diag\left[\sigma_h^2,\sigma_h^2,\sigma_v^2  \right]$. If the \texttt{SMOOTH\_IN\_KM} is set to 1, the $\sigma_{h,v}$ will be in km. And the $\bm{x}$ is the true coordinates. If not, $\bm{x}$ are the integer indices.
\item \texttt{ITER\_START} Only use previous models after this iteration in NLCG/L-BFGS inversion. This value MUST be updated to the current iteration number if you're trying to update your model by trying a new set of smoothing parameters.
\item \texttt{MAX\_REL\_STEP} In NLCG/L-BFGS inversion, we usually do line search to find the best model in each iteration. Although we've implemented some methods to estimate the line search step size, we use this parameter to set the maximum relative variation of the new model to the previous one. Usually 0.03 or 0.04 is enough.
\end{description}

\subsection{Initial Model and True Model File}
\texttt{Please Note that the format of MOD.true in current version 
is different from previous versions!} \\ 

The initial and true model are called \verb!MOD! 
and \verb!MOD.true! respectively in this instruction. 
They are used for initial input model, 
and for synthetic test dataset (like in checkerboard test). 
The format of these two files are listed below: \\
 The first line contains 
three integers which denote the number of grid points
in latitude,longitude,and in 
depth respectively. The second line denotes coordinates 
of the origin point (NorthWest point), in degree. The third 
line denotes the grid interval in latitudinal and 
longitudinal direction, both in degree. Then the next line 
are depths (in km) of each grid points,
i.e. there would be \texttt{nz} numbers in this line. 
The subsequent lines of \verb!MOD! are shear wave velocities.
If we store the velocity with the format V(nz,nlon,nlat)
(Row-major,where $V(0,0,0)$ is the shear-wave velocity of the 
\texttt{top NorthWest} point at \texttt{dep(0)} km, and V(nz-1,nlon-1,nlat-1) is 
the velocity of \texttt{bottom SouthEast} point at dep(nz-1) km), then it 
should be print to MOD as following:
\begin{lstlisting}[language=python]
//python
f = open("MOD","W")
for i in range(nz):
    for j in range(nlon):
        for k in range(nlat):
            f.write("%f "%(V[i,j,k]))
        f.write("\n")
\end{lstlisting}

\subsection{Dispersion Data File}
This dispersion data in \verb!example/! is surfdataSC.dat,
which contains dispersion (distance/traveltime) data. Here we list the first several lines:\\
1 19		 \verb!#! Rayleigh Phase \\
4 6 8 10 12 14 16 18 20 22 24. 26 28 30 32 34 36 38 40 \\
1 19		 \verb!#! Rayleigh Group \\
4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40  \\
0		\verb!#! Love Phase \\
0		 \verb!#! Love group \\
\verb!#!  31.962600 108.646000 0 1 2 0\\
33.732800 105.764100 3.0840\\
34.342500 106.020600 3.1154\\
33.357400 104.991700 3.0484\\
33.356800 106.139500 3.0820\\
34.128300 107.817000 3.1250\\
33.229300 106.800200 3.0575\\
\verb!#! 29.905000 107.232500 0 1 2 0\\
34.020000 102.060100 2.7532\\

This file contains three kinds of information. The data header, source or master station (lines begin with
\verb!#!) and receiver stations (without \verb!#! in each
line).

The data header contains the dispersion data description of wave type and period information.  The first line contains the number of modes $n$ (the first number) will be used for Rayleigh wave phase velocity. Followed this number are $n$ numbers which indicate the number of period points this mode will use. Then there will be $n$ lines contain the period information.  For example, if you want to use the fundamental and first mode dispersion data with period [4,7.5,10]s and [3,4]s respectively, the header should be like: \\ \\ 
2 3 2 \verb!#! rayleigh phase \\
4 7.5 10 \\ 
3 4 \\

Then you can add information for other wave/velocity types. If no data of this wave type will be used, the line will contain only a number 0.\\

For a source or master station, the format of 
this line is:
\begin{center}
    \verb!#! \texttt{latitude longitude mode period-index wavetype
     velotype}
\end{center}

\begin{itemize}
    \item \texttt{mode} mode index. 0 for fundamental and 1 for the first order ...
    \item \texttt{wavetype}: the type of surface wave, for 
                            Rayleigh it is 2, and it is 1 for Love wave.
    \item \texttt{velotype}: velocity type, 0 for phase velocity
                            and 1 for group velocity.
    \item \texttt{period-index}: The period index number, start from 1.
\end{itemize}
For example, if in our dataset, the dispersion periods 
for fundamental mode Rayleigh phase velocity is at periods 4s,5s,6s,7s, 
and this line contains information only at 5s, then 
the last 4 numbers 
are \texttt{0,2,2,0}.\\

Then the following lines contain all the receiver stations
that you have successfully extracted dispersion curves
at this period, this wave type and this velocity type.
And the format of each line is:
\begin{center}
    \texttt{latitude longitude  dispersion}
\end{center} 


\subsection{Run This Module}
After you have prepared all the required files in a folder,
then you could enter into this folder,and run this command
in your shell:
\begin{lstlisting}[language=bash]
./DSurfTomo -h
\end{lstlisting}
Then you could type in all required files according to the 
order on the screen.

\subsection{Output Files}\label{surface wave output files}
This module will output one  folder: \verb!results/!.  It contains all the intermediate models  (\verb!mod_iter*!) and data files (\verb!res*.dat!) for each iteration. There may be some temporary binary files (\verb!*.bin!) that contains the optimization history of NLCG/L-BFGS optimization.
The format of model file is:
\begin{center}
    \texttt{longitude latitude depth Vs},   
\end{center}
And the format of traveltime file is (9 columns): 
\begin{center}
    \small{\texttt{distance observation synthetic lat1 lon1 lat2 lon2 
    period wavetype}}.
\end{center}

\section{Joint Inversion Module}
This module needs 4-6 files in total:
\begin{itemize}
    \item \verb!JointSG.in!: contains information of input model,
            dispersion data and inversion parameters.
    \item \verb!surfdataSC.dat!: surface wave dispersion data.
    \item \verb!obsgrav.dat!: Gravity anomaly dataset.
    \item \verb!gravmat.dat!: sensitivity kernel of 
                gravity to density.
    \item \verb!MOD!: Initial model.
    \item \verb!MOD.true!: checkerboard model.
    \item \texttt{MOD.ref}: gravity reference model, used 
            for compute gravity anomaly.
\end{itemize}
Here are the formats of each file.

\subsection{Parameter File}
There are only subtle differences between \verb!JointSG.in! and \verb!DSurfTomo.in! : 
\begin{lstlisting}
# synthetic test 
NOISE_LEVEL_SWD  =  1.5 #  swd noise level
NOISE_LEVEL_GRAV =  5.  # gravity noise level 
WEIGHT_SWD       =  1.5
WEIGHT_GRAV      =  5.
RELATIVE_P       =  0.5   # relative factor

# remove averge value of gravity 
REMOVE_AVG  = 1 
\end{lstlisting}

To know the meaning of each parameter, here I list the weighted cost function of joint inverse 
problem \citep{Julia2000}:
\[
    L = \frac{p}{N_1 \sigma_1^2}\sum_{i=1}^{N_1} (d_{1,i}- 
        d_{1,i}^o)^2 +   
        \frac{1-p}{N_2 \sigma_2^2} \sum_{i=1}^{N_2}
        (d_{2,i}- d_{2,i}^o)^2 \tag{1}
\]
where $\mathbf{d}_{1,2}$ is the data vector for each dataset. $N_{1,2}$
is the size of each dataset and $\sigma_{1,2}$ (The \texttt{WEIGTH\_SWD} and \texttt{WEIGHT\_GRAV} in \texttt{JointSG.in}) is the corresponding
errors. $p$ (\texttt{RELATIVE\_P}) is a parameter in the range [0,1] to control the contribution
of each dataset manually. \\

The additional parameter is \texttt{REMOVE\_AVG}. When this integer is equal to 1, the program will automatically 
remove the average value of observed and synthetic gravity data. This option is applied to remove large-scale density anomalies 
in the deep mantle. For more details please refer to \ref{Gravref}.

\subsection{Gravity Data File}
The format of this file is quite simple, just print all 
the gravity data to this file. Each line of it contains 
the longitude,latitude and gravity anomaly at this point. \\

Here I list the first 9 lines of this file to give you
an example:\\
100.000000 35.000000 -224.206921\\
100.000000 34.950000 -224.110699\\
100.000000 34.900000 -241.774731\\
100.000000 34.850000 -240.245968\\
100.000000 34.800000 -234.187542\\
100.000000 34.750000 -246.670605\\
100.000000 34.700000 -238.575939\\
100.000000 34.650000 -241.357250\\
100.000000 34.600000 -260.059429\\

\subsection{Gravity Matrix File}
This file is generated by gravity module, please refer to 
chapter \ref{Gravity Matrix}.

\subsection{Gravity Reference Model File}\label{Gravref}
Based on the definition of gravity anomaly, it reflects the 
density perturbs according to a normal ellipsoid. Thus we need 
to convert the absolute anomalies to local anomalies in our research 
area. Before inversion, we will remove the average value of 
observed anomalies. So in the real data 
inversion, there are 3 steps to compute relative anomalies:
\begin{itemize}
    \item Compute density distribution of 
        current S-wave model and reference model (through
        empirical relations).
    \item Compute density anomaly, then utilize gravity matrix
          to get gravity anomalies.
    \item Remove average value of the synthetic anomaly data.
\end{itemize}
This model could be a user self-defined model, and you could also use the 
default one (the average of initial model in every depth). Please 
remember, when you are tackling real data, to set the \texttt{REMOVE\_AVG} to 1 in \texttt{JointSG.in} file. 

\subsection{Run This Module}
After you have prepared all these required files in a directory, 
then you can enter into this folder, and run this command 
in your shell:
\begin{lstlisting}[language=bash]
./JointSG -h
\end{lstlisting}
Then you could type in all required files according to the 
order on the screen.

\subsection{Output Files}
This module will print some files in the directory: 
\verb!resultsJ/!. \\

The format of \verb!kernel/! is the same as the files
in \ref{surface wave output files}. In the folder \verb!results/!,
it contains models (\verb!joint_mod_iter*!), 
surface wave travel time (\verb!res_surf*.dat!) and 
gravity anomaly (\verb!res_grav*.dat!) 
of each iteration. The format of gravity anomaly is:
\begin{center}
    \texttt{lon lat observed-anomalies synthetic-anomalies}
\end{center}

\section{Gravity Module}
This module requires two input files:
\begin{itemize} 
    \item \texttt{MOD} : only the header and depth information are needed.
    \item \texttt{obsgrav.dat}: contains coordinates of each 
                     obeservation points.
\end{itemize}
These formats have been illustrated in previous chapters.

\subsection{Run This Module}
After you prepare all these required files in a folder,
then you could enter into this folder,and print in your shell:
\begin{lstlisting}[language=bash]
./mkmat -h
\end{lstlisting}
Then you could type in all required files according to 
the order on the screen.

\subsection{Output Files}\label{Gravity Matrix}
This module output only one file: \verb!gravmat.bin!. 
This is the derivative matrix for gravity anomaly. It is a 
a Compressed Sparse Row Matrix (CSR format). If you want to know how to read this file, please refer to the code in \texttt{src/shared/csr\_matrix.cpp}.


\section{Advanced Options}

\subsection{OpenMP Mode}
All the 4 programs can be executed on a single node with OpenMP support. To choose the number of threads used, you can set this environment variable before running any programs:
\begin{lstlisting}[language=bash]
export OMP_NUM_THREADS=8
\end{lstlisting}
The maximum number of threads depends on your own platform. You can use the command :
\begin{lstlisting}[language=bash]
cat /proc/cpuinfo |grep cores |wc -l
\end{lstlisting}
The maximum number of threads is \texttt{half} of the output number from the above command. 

\subsection{Empirical Relations}
Empirical relations are utilized to connect density and 
velocity of rocks in our program. If you have better relations 
in your study area, you can change this relation 
in \verb!src/SWD/exmpirical.cpp! 
\begin{lstlisting}[language=c++]
void empirical_relation(float vsz,float &vpz,float &rhoz)
{
    vpz = 0.9409 + 2.0947*vsz - 0.8206*pow(vsz,2)+ 
            0.2683*pow(vsz,3) - 0.0251*pow(vsz,4);
    rhoz = 1.6612 * vpz - 0.4721 * pow(vpz,2) + 
            0.0671 * pow(vpz,3) - 0.0043 * pow(vpz,4) + 
            0.000106 * pow(vpz,5);
}
\end{lstlisting}
And if you want to conduct joint inversion, please remember to
change the derivative function in the same file.

\subsection{Random Seed}
In our program, to make sure the generated random number the same
in each independent numerical experiments, we fix the random seed
in \texttt{src/utils/gaussian.cpp}:
\begin{lstlisting}[language=c++]
static default_random_engine e(11);
\end{lstlisting}
You could change 11 to other integer if required.

\section{Tips and Tools}
\subsection{Warnings}
In fact, \texttt{DSurfTomo} and \texttt{JointSG} are all dependent 
on two modules. First one is the forward computation of dispersion 
curves from 1-D model, and another one is the ray-tracing on 
2-D spherical surface. There would be some possible errors in these 
two modules due to incompatible input model format, terrible initial 
model, and even the inappropriate location of your stations. To tackle possible 
problems, the two modules will print some information on the screen 
or in a output file to help you debug.

The first possible warning is \texttt{"WARNING:improper initial value in 
disper-no zero found"} on the screen. Then a \texttt{fort.66} file will 
be generated in the running directory. This error is due to 
a strange 1-D model that the dispersion module cannot find 
dispersion curves for this model. There are some possible reasons for 
this warning. If you find this problem for the first iteration,
this problem may from that the format of your initial model 
is different from the required one. You could check the model in 
file \texttt{fort.66} and compare that with your model. 
Another possible reason is that you take inappropriate 
Tikhonov regularization parameters (i.e. damping and smooth factors)
which lead to abrupt change of previous model.

The second warning is \texttt{"Source lies outside bounds 
of model (lat,long)="}.
This reason is caused by that the receivers are too close to 
the boundary of the current model that ray paths are along 
this boundary. If this warning happens, please enlarge your 
model to avoid this problem.

\subsection{L-curve Analysis}
Usually L-curve analysis is applied to determine the best 
suitable smoothing and damping factor for a inverse problem. In our 
numerical experiment, we find that the damping factor affects the 
final result smaller than smoothing factor. So we \texttt{recommend}
you to keep the damping factor to a small value (such as 0.001) during 
your inversion, and only tune the smoothing factor. 


In the folder \texttt{utils/}, we have prepared one python script \texttt{utils/lcurve.py} to help 
you tune the smoothing factor. The script will output the roughness of the inverted model $\|L(m-m_0)\|_2$ and $\|m-m_0\|_2$

\subsection{Checkpoint Restart}
Sometimes you want to start from one of the results (like mod\_iter5.dat)
instead of the initial model. We prepared a python script
\texttt{utils/out2init.py}, you could run this script like this 
\begin{lstlisting}
python out2init.py mod_iter5.dat MOD05 
\end{lstlisting}
Then this script will convert the output model to the format 
of the initial model. This script will be useful in joint inversion.
And also, it may help you restart from some checkpoint if some issues 
happened.

% biblio GJI
\bibliographystyle{abbrvnat}
\bibliography{bibliography}
\end{document}
